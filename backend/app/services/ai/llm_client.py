"""
å¤§æ¨¡å‹å®¢æˆ·ç«¯ - DeepSeek/é€šä¹‰åƒé—®
"""
from typing import Optional, List, Dict, Any
from openai import AsyncOpenAI
from app.config import settings
from app.utils.logger import logger
import aiohttp


class LLMClient:
    """å¤§æ¨¡å‹å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.provider = "deepseek"
        self.client = None
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        try:
            def _normalize_url(url: str) -> str:
                if not url:
                    return url
                u = url.strip()
                # ä¿®æ­£å¸¸è§ç²˜è´´é”™è¯¯ï¼šä¸­æ–‡é€—å·/è‹±æ–‡é€—å·/ç©ºæ ¼
                u = u.replace('ï¼Œ', ',').replace(' ', '')
                u = u.replace(',', '.')
                # å»æ‰é‡å¤çš„æ–œæ 
                while '//' in u[8:]:
                    u = u.replace('//', '/').replace(':/', '://')
                return u

            base_url = _normalize_url(settings.DEEPSEEK_BASE_URL)
            if settings.DEEPSEEK_API_KEY:
                self.client = AsyncOpenAI(
                    api_key=settings.DEEPSEEK_API_KEY,
                    base_url=base_url
                )
                safe_key = settings.DEEPSEEK_API_KEY[:6] + "***"
                logger.info(f"âœ… LLMåˆå§‹åŒ–æˆåŠŸ provider=ark base_url={base_url} model={settings.DEEPSEEK_MODEL} key={safe_key}")
            else:
                logger.warning("âš ï¸ æœªé…ç½®DEEPSEEK_API_KEYï¼ŒLLMåŠŸèƒ½å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        except Exception as e:
            logger.error(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.client = None
    
    async def chat_with_messages(self,
                                 messages: List[Dict[str, str]],
                                 temperature: float = 0.7,
                                 max_tokens: int = 2000) -> Optional[str]:
        """
        å¯¹è¯æ¥å£
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ [{"role": "user", "content": "..."}]
            temperature: æ¸©åº¦ï¼ˆ0-1ï¼‰
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            AIå›å¤æ–‡æœ¬
        """
        try:
            if not self.client:
                # æ²¡æœ‰SDKå®¢æˆ·ç«¯ï¼Œå°è¯•HTTPç›´è¿
                http_reply = await self._chat_via_http(messages, temperature, max_tokens)
                if http_reply:
                    return http_reply
                return await self._chat_fallback(messages)
            
            response = await self.client.chat.completions.create(
                model=settings.DEEPSEEK_MODEL,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            reply = response.choices[0].message.content
            logger.info(f"âœ… LLMå›å¤æˆåŠŸ (tokens: {response.usage.total_tokens})")
            
            return reply
            
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            # SDKå¤±è´¥æ—¶ï¼Œå°è¯•HTTPç›´è¿
            http_reply = await self._chat_via_http(messages, temperature, max_tokens)
            if http_reply:
                return http_reply
            return await self._chat_fallback(messages)
    
    async def chat_with_functions(self,
                                  messages: List[Dict[str, str]],
                                  functions: List[Dict],
                                  function_call: str = "auto") -> Optional[Dict]:
        """
        å¸¦Function Callingçš„å¯¹è¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            functions: å¯ç”¨å‡½æ•°åˆ—è¡¨
            function_call: å‡½æ•°è°ƒç”¨ç­–ç•¥
            
        Returns:
            {"reply": "æ–‡æœ¬", "function_call": {...}} æˆ– None
        """
        try:
            if not self.client:
                return await self._chat_fallback(messages)
            
            response = await self.client.chat.completions.create(
                model=settings.DEEPSEEK_MODEL,
                messages=messages,
                functions=functions,
                function_call=function_call,
                temperature=0.7
            )
            
            choice = response.choices[0]
            
            result = {
                "reply": choice.message.content,
                "function_call": None
            }
            
            if choice.message.function_call:
                result["function_call"] = {
                    "name": choice.message.function_call.name,
                    "arguments": choice.message.function_call.arguments
                }
                logger.info(f"ğŸ”§ Function Call: {result['function_call']['name']}")
            
            return result
            
        except Exception as e:
            logger.error(f"LLM Function Callingå¤±è´¥: {e}")
            return None
    
    async def _chat_fallback(self, messages: List[Dict[str, str]]) -> str:
        """é™çº§æ–¹æ¡ˆï¼šç®€å•è§„åˆ™å¼•æ“"""
        user_message = messages[-1]["content"] if messages else ""
        
        # ç®€å•çš„è§„åˆ™åŒ¹é…
        if "æ‰“å¼€" in user_message:
            return "å¥½çš„ï¼Œæˆ‘å°†ä¸ºæ‚¨æ‰“å¼€åº”ç”¨ç¨‹åºã€‚"
        elif "æœç´¢" in user_message or "æŸ¥æ‰¾" in user_message:
            return "å¥½çš„ï¼Œæˆ‘å°†ä¸ºæ‚¨æœç´¢ç›¸å…³å†…å®¹ã€‚"
        elif "æ’­æ”¾" in user_message:
            return "å¥½çš„ï¼Œæˆ‘å°†ä¸ºæ‚¨æ’­æ”¾éŸ³ä¹ã€‚"
        elif "åˆ›å»º" in user_message or "æ–°å»º" in user_message:
            return "å¥½çš„ï¼Œæˆ‘å°†ä¸ºæ‚¨åˆ›å»ºæ–‡ä»¶ã€‚"
        elif "å…³é—­" in user_message:
            return "å¥½çš„ï¼Œæˆ‘å°†å…³é—­åº”ç”¨ã€‚"
        elif "å‡†å¤‡å·¥ä½œ" in user_message:
            return "å¥½çš„ï¼Œæˆ‘å°†ä¸ºæ‚¨å‡†å¤‡å·¥ä½œç¯å¢ƒï¼šæ‰“å¼€å¼€å‘å·¥å…·ã€æµè§ˆå™¨å’Œæ’­æ”¾èƒŒæ™¯éŸ³ä¹ã€‚"
        else:
            return "æˆ‘ç†è§£äº†ï¼Œè®©æˆ‘æ¥å¸®æ‚¨å¤„ç†ã€‚"

    async def _chat_via_http(self, messages: List[Dict[str, str]], temperature: float, max_tokens: int) -> Optional[str]:
        """ç›´æ¥é€šè¿‡HTTPè°ƒç”¨ OpenAIå…¼å®¹æ¥å£ï¼Œé¿å…SDKå…¼å®¹é—®é¢˜ã€‚"""
        if not settings.DEEPSEEK_API_KEY or not settings.DEEPSEEK_BASE_URL:
            return None
        base_url = settings.DEEPSEEK_BASE_URL.strip().replace('ï¼Œ', ',').replace(' ', '').replace(',', '.')
        url = f"{base_url.rstrip('/')}/chat/completions"
        headers = {
            "Authorization": f"Bearer {settings.DEEPSEEK_API_KEY}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": settings.DEEPSEEK_MODEL,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }
        try:
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(url, headers=headers, json=payload) as resp:
                    text = await resp.text()
                    if resp.status == 200:
                        data = await resp.json()
                        reply = data["choices"][0]["message"]["content"]
                        logger.info("âœ… HTTPç›´è¿LLMæˆåŠŸ")
                        return reply
                    logger.error(f"LLM HTTPé”™è¯¯ {resp.status}: {text}")
                    return None
        except Exception as e:
            logger.error(f"LLM HTTPç›´è¿å¤±è´¥: {e}")
            return None
    
    def is_available(self) -> bool:
        """æ£€æŸ¥LLMæ˜¯å¦å¯ç”¨"""
        return self.client is not None
    
    async def chat(self, user_input: str) -> str:
        """ç®€å•çš„èŠå¤©æ¥å£"""
        messages = [
            {"role": "system", "content": "ä½ æ˜¯VoicePCæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æ§åˆ¶ç”µè„‘å’Œå›ç­”é—®é¢˜ã€‚"},
            {"role": "user", "content": user_input}
        ]
        return await self.chat_with_messages(messages)


# å…¨å±€å®ä¾‹
llm_client = LLMClient()

